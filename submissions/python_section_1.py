# -*- coding: utf-8 -*-
"""python_section_1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zk_i-ZwsI6DrvRFYT5TGsHw_ON_59lgd
"""

# Install the 'polyline' library to decode Google Maps polylines
!pip install polyline

from typing import Dict, List
import pandas as pd
import re
import polyline
import ast
from datetime import datetime, timedelta
import numpy as np

# Question 1:
def reverse_by_n_elements(lst: List[int], n: int) -> List[int]:
    """
    Reverses the input list by groups of n elements.
    """
    # Your code goes here.
    result = []

    for i in range(0, len(lst), n):
        # Reverse the current group of 'n' elements and add to result
        result.extend(lst[i:i+n][::-1])

    return result

print(reverse_by_n_elements([1, 2, 3, 4, 5, 6, 7, 8], 3))

print(reverse_by_n_elements([1, 2, 3, 4, 5], 2))

print(reverse_by_n_elements([10, 20, 30, 40, 50, 60, 70], 4))

# Question 2:
def group_by_length(lst: List[str]) -> Dict[int, List[str]]:
    """
    Groups the strings by their length and returns a dictionary where keys are lengths and values are lists of strings.
    """
    length_dict = {}

    # Iterate through each string in the list
    for string in lst:
        length = len(string)  # Get the length of the string
        # If the length is not already a key in the dictionary, add it
        if length not in length_dict:
            length_dict[length] = []
        # Append the string to the corresponding list of that length
        length_dict[length].append(string)

    # Return a dictionary sorted by the keys (lengths)
    return dict(sorted(length_dict.items()))

print(group_by_length(["apple", "bat", "car", "elephant", "dog", "bear"]))

print(group_by_length(["one", "two", "three", "four"]))

# Question 3:
def flatten_dict(nested_dict: Dict, sep: str = '.', parent_key = '') -> Dict:
    """
    Flattens a nested dictionary into a single-level dictionary with dot notation for keys.

    :param nested_dict: The dictionary object to flatten
    :param sep: The separator to use between parent and child keys (defaults to '.')
    :param parent_key: Keeps track of the parent key during recursion (defaults to empty string)
    :return: A flattened dictionary
    """
    # Dictionary to hold the flattened key-value pairs
    items = {}
    # Loop through each key-value pair in the original dictionary
    for key, value in nested_dict.items():
        # Combine the parent key with the current key, separated by 'sep'
        new_key = f"{parent_key}{sep}{key}" if parent_key else key

        # If the value is a dictionary, recurse to flatten it further
        if isinstance(value, dict):
            items.update(flatten_dict(value, sep, new_key))

        # If the value is a list, treat each element in the list as a separate dictionary with the index as the key
        elif isinstance(value, list):
            for i, v in enumerate(value):
                # Recursively flatten each element of the list
                items.update(flatten_dict({str(i): v}, sep, f"{new_key}"))

        # If the value is neither a dictionary nor a list, just add it to the result dictionary
        else:
            items[new_key] = value

    # Return the fully flattened dictionary
    return items

nested_dict = {
    "road": {
        "name": "Highway 1",
        "length": 350,
        "sections": [
            {
                "id": 1,
                "condition": {
                    "pavement": "good",
                    "traffic": "moderate"
                }
            }
        ]
    }
}

flattened = flatten_dict(nested_dict)
print(flattened)

# Question 4:
def unique_permutations(nums: List[int]) -> List[List[int]]:
    """
    Generate all unique permutations of a list that may contain duplicates.

    :param nums: List of integers (may contain duplicates)
    :return: List of unique permutations
    """
    # Your code here
    # List to store all unique permutations
    result = []

    # Helper function for backtracking
    def backtrack(path, used):
        # When the path has all the elements, add it as a valid permutation
        if len(path) == len(nums):
            result.append(path[:])
            return

        # Iterate over the numbers to form permutations
        for i in range(len(nums)):
            # Skip used numbers or duplicate numbers (to ensure uniqueness)
            if used[i] or (i > 0 and nums[i] == nums[i - 1] and not used[i - 1]):
                continue

            # Mark the current number as used and add to the path
            used[i] = True
            path.append(nums[i])

            # Recurse with the updated path and used array
            backtrack(path, used)

            # Backtrack by removing the last number and unmarking it
            path.pop()
            used[i] = False

    # Start the backtracking with an empty path and 'used' flag array
    backtrack([], [False] * len(nums))

    return result

input_list = [1, 1, 2]
permutations = unique_permutations(input_list)
for perm in permutations:
    print(perm)

# Question 5:
def find_all_dates(text: str) -> List[str]:
    """
    This function takes a string as input and returns a list of valid dates
    in 'dd-mm-yyyy', 'mm/dd/yyyy', or 'yyyy.mm.dd' format found in the string.

    Parameters:
    text (str): A string containing the dates in various formats.

    Returns:
    List[str]: A list of valid dates in the formats specified.
    """
    # Define a regex pattern to match dates in the following formats:
    # 'dd-mm-yyyy' or 'dd.mm.yyyy', 'mm/dd/yyyy', or 'yyyy-mm-dd' or 'yyyy.mm.dd'
    date_pattern = r'\b(?:\d{2}[.-]\d{2}[.-]\d{4}|\d{2}/\d{2}/\d{4}|\d{4}[.-]\d{2}[.-]\d{2})\b'
    # Use 're.findall' to find all matching dates in the input string
    dates = re.findall(date_pattern, text)
    # Return the list of dates found
    return dates

text = "I was born on 23-08-1994, my friend on 08/23/1994, and another one on 1994.08.23."
dates1 = find_all_dates(text)
print(dates1)

# Question 6:
def haversine(lat1, lon1, lat2, lon2):

    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])

    dlon = lon2 - lon1
    dlat = lat2 - lat1
    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
    c = 2 * np.arcsin(np.sqrt(a))
    r = 6371000  # Radius of Earth in meters
    return c * r

def polyline_to_dataframe(polyline_str: str) -> pd.DataFrame:
    """
    Converts a polyline string into a DataFrame with latitude, longitude, and distance between consecutive points.

    Args:
        polyline_str (str): The encoded polyline string.

    Returns:
        pd.DataFrame: A DataFrame containing latitude, longitude, and distance in meters.
    """

    coordinates = polyline.decode(polyline_str)

    df = pd.DataFrame(coordinates, columns=['latitude', 'longitude'])

    distances = [0]  # First point has distance 0
    for i in range(1, len(df)):
        dist = haversine(df.iloc[i-1]['latitude'], df.iloc[i-1]['longitude'],
                         df.iloc[i]['latitude'], df.iloc[i]['longitude'])
        distances.append(dist)

    df['distance'] = distances

    return df

polyline_input = input("Input: ")
output_df = polyline_to_dataframe(polyline_input)
print("Output DataFrame:")
print(output_df)

# Question 7:
def rotate_and_transform_matrix(matrix: List[List[int]]) -> List[List[int]]:
    """
    Rotate the given matrix by 90 degrees clockwise, then multiply each element
    by the sum of its original row and column index before rotation.

    Args:
    - matrix (List[List[int]]): 2D list representing the matrix to be transformed.

    Returns:
    - List[List[int]]: A new 2D list representing the transformed matrix.
    """
    # Your code here
    n = len(matrix)

    rotated_matrix = [[0] * n for _ in range(n)]  # Initialize a new matrix for rotation
    for i in range(n):
        for j in range(n):
            rotated_matrix[j][n - 1 - i] = matrix[i][j]

    print(f"rotated_matrix = {rotated_matrix}")

    transformed_matrix = [[0] * n for _ in range(n)]

    for i in range(n):
        for j in range(n):
            row_sum = sum(rotated_matrix[i]) - rotated_matrix[i][j]
            col_sum = sum(rotated_matrix[k][j] for k in range(n)) - rotated_matrix[i][j]
            transformed_matrix[i][j] = row_sum + col_sum

    print(f"final_matrix = {transformed_matrix}")

    return transformed_matrix

def main():
    user_input = input("Input: ")

    matrix = ast.literal_eval(user_input)

    output_matrix = rotate_and_transform_matrix(matrix)

if __name__ == "__main__":
    main()

# Question 8:
def time_check(df)->pd.Series:
    """
    Use shared dataset-2 to verify the completeness of the data by checking whether the timestamps for each unique (`id`, `id_2`) pair cover a full 24-hour and 7 days period

    Args:
        df (pandas.DataFrame)

    Returns:
        pd.Series: return a boolean series
    """
    # Write your logic here
    # combining startDay , startTime columns into one column
    df['start_timestamp'] = pd.to_datetime(df['startDay'] + ' ' + df['startTime'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

    # combining endDay , endTime columns into one column
    df['end_timestamp'] = pd.to_datetime(df['endDay'] + ' ' + df['endTime'], format='%Y-%m-%d %H:%M:%S', errors='coerce')

    # grouping by (`id`, `id_2`) and check completeness
    completeness_check = (
        df.groupby(['id', 'id_2'])
        .apply(lambda group: (
            (group['start_timestamp'].min() == pd.Timestamp('00:00:00')) and
            (group['end_timestamp'].max() == pd.Timestamp('23:59:59')) and
            (len(group['start_timestamp'].dt.dayofweek.unique()) == 7)
        ))
    )

    return completeness_check


#Testing time_check function:
df= pd.read_csv('/content/dataset-1.csv')
result = time_check(df)
print(result)